{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISLDS PROJECT--Glass Data Prediction<br>\n",
    "#### Information and Computing Sciences 2020 Fu Yinmingren"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis<br>\n",
    "There are 283,104 raw glass data with a total of 794 different characteristics, including characteristics such as glass composition (monomer or compound), viscosity, density, Young's modulus, Abbe number, refractive index, transition temperature, etc. For such a huge amount of data and features, data pre-processing is very necessary. For this project, I chose the feature density293K as the response variable and all the oxide features as predictor variables<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing<br>\n",
    "For the raw data, I did the following pre-processing steps:<br>\n",
    "(1)Delete feature columns except for Density293K<br>\n",
    "(2)Delete all non-oxide and monomer columns<br>\n",
    "(3)Delete rows and columns with all zeros<br>\n",
    "(4)Delete abnormal data (abnormally large value for one row in column Density293K)<br>\n",
    "\n",
    "After the above processing, the dataset still has 9w+ data and 100+ features left, next, to remove the redundant features among them and simplify the process, delete the columns with less than 500 data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.feature_selection import chi2,SelectKBest\n",
    "from sklearn.model_selection import cross_val_score,ShuffleSplit,RandomizedSearchCV,learning_curve,train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "raw_data=pd.read_csv(\"D:\\课件\\统计学习与数据科学导论\\数据预处理\\Data_Glasses.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecessary data\n",
    "pre_data=raw_data.drop(raw_data.columns[759:794],axis=1) # Delete property columns except for Density293K\n",
    "pre_data=pre_data.drop(pre_data.columns[702:758],axis=1) # Delete property columns except for Density293K\n",
    "pre_data.iloc[0,0]='O'\n",
    "fin_data=pre_data.loc[:,pre_data.iloc[0].str.contains('O')] # Deletion of non-oxide substances\n",
    "temp_data=pre_data.iloc[:,702]\n",
    "\n",
    "fin_data=pd.concat([fin_data,pre_data.iloc[:,702]],axis=1) # Get all the data of the oxide Density293K\n",
    "fin_data=fin_data.dropna(subset=[fin_data.columns[198]]) # Delete empty rows in column Density293K\n",
    "\n",
    "fin_data=fin_data.iloc[:,1:] # Change the name of the first row as the column name\n",
    "fin_data.columns=fin_data.iloc[0]\n",
    "fin_data=fin_data[1:].reset_index(drop=True)\n",
    "\n",
    "fin_data=fin_data.loc[(fin_data.sum(axis=1) != 0),:] # Delete data with all rows 0\n",
    "fin_data=fin_data.drop(fin_data.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_data.to_csv('preprocess_data_v1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"D:\\课件\\统计学习与数据科学导论\\数据预处理\\preprocess_data.csv\")\n",
    "x_colums=data.columns[0:-1]\n",
    "y_colums=data.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "test_data=data\n",
    "for i in x_colums[:]:\n",
    "    num=0\n",
    "    temp=data[i]\n",
    "    for j in range(len(temp)):\n",
    "        if temp[j] != 0:\n",
    "            num+=1\n",
    "    if num<500:\n",
    "        #print(i,\":\",num)\n",
    "        count+=1\n",
    "        test_data=test_data.drop(i,axis=1)\n",
    "#print(count)\n",
    "\n",
    "print(test_data.head)\n",
    "x_colums=test_data.columns[0:-1]\n",
    "y_colums=test_data.columns[-1]\n",
    "total_colums=test_data.columns\n",
    "print(x_colums)\n",
    "print(y_colums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the pre-processed data\n",
    "test_data.to_csv('preprocess_data_1.csv',index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After further pre-processing as described above, the dataset is left with 98,373 data and 49 features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"H:\\Python_Project\\ISLDS\\preprocess_data_1.csv\") # Read pre-processed data\n",
    "x_colums=data.columns[0:-1]\n",
    "y_colums=data.columns[-1]\n",
    "total_colums=data.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot histograms and scatter plots for each feature versus response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw histogram\n",
    "def hist(data):\n",
    "    data.hist(figsize=(30,30))\n",
    "    plt.show()\n",
    "\n",
    "hist(data[total_colums])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  .image-container {\n",
    "    text-align: center; /* 图片及标题居中对齐 */\n",
    "  }\n",
    "  .image-container img {\n",
    "    width: 1200px; /* 设置图片宽度为300像素 */\n",
    "    height: auto; /* 根据宽度自动调整高度 */\n",
    "  }\n",
    "  .image-container figcaption {\n",
    "    font-size: 20px; /* 设置标题文字大小为14像素 */\n",
    "    font-weight: bold; /* 设置标题文字加粗 */\n",
    "    margin-bottom: 10px; /* 设置标题上方距离为10像素 */\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<figure class=\"image-container\">\n",
    "  <figcaption>Histogram Plot</figcaption><img src=\"hist.png\" alt=\"图片描述\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting scatter plots\n",
    "def scatter(data):\n",
    "    for i in total_colums[:70]:\n",
    "         plt.scatter(data[i],data['Density293K'])\n",
    "         plt.xlabel(i)\n",
    "         plt.ylabel('Density293K')\n",
    "         plt.show()\n",
    "scatter(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  .image-container {\n",
    "    text-align: center; /* 图片及标题居中对齐 */\n",
    "  }\n",
    "  .image-container img {\n",
    "    width: 800px; /* 设置图片宽度为300像素 */\n",
    "    height: auto; /* 根据宽度自动调整高度 */\n",
    "    padding-right: 10px; /* 设置图片右侧间隔为10像素 */\n",
    "  }\n",
    "  .image-container figcaption {\n",
    "    font-size: 20px; /* 设置标题文字大小为14像素 */\n",
    "    font-weight: bold; /* 设置标题文字加粗 */\n",
    "    margin-bottom: 5px; /* 设置标题上方距离为10像素 */\n",
    "  }\n",
    "\n",
    "</style>\n",
    "\n",
    "<figure class=\"image-container\">\n",
    "  <figcaption>SiO2</figcaption><img src=\"sio2.png\" alt=\"图片描述\">\n",
    "  <figcaption>GeO2</figcaption><img src=\"geo2.png\" alt=\"图片描述\">\n",
    "  <figcaption>Ga2O3</figcaption><img src=\"ga2o3.png\" alt=\"图片描述\">\n",
    "</figure>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the processed dataset for regression prediction, the dataset is first normalized and then randomly divided into training set test set division<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）Dataset division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set training set division\n",
    "train_set,test_set=train_test_split(data.to_numpy(),test_size=0.2,random_state=25)\n",
    "# print(train_set.shape)\n",
    "# print(test_set.shape)\n",
    "x_train=train_set[:,0:49]\n",
    "y_train=train_set[:,-1]\n",
    "x_test=test_set[:,0:49]\n",
    "y_test=test_set[:,-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of data\n",
    "scaler_x = StandardScaler()\n",
    "x_train = scaler_x.fit_transform(x_train)\n",
    "x_test = scaler_x.transform(x_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = scaler_y.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression prediction using nonlinear SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using non-linear SVM\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': [0.1, 0.01, 0.001],\n",
    "}\n",
    "SVM_Model=SVR(kernel='rbf',C=10,gamma=0.1)\n",
    "# SVM_random_cv=RandomizedSearchCV(estimator=SVM_Model,param_distributions=param_grid,scoring='r2',cv=3,n_iter=10,n_jobs=-1)\n",
    "SVM_Model.fit(x_train,y_train)\n",
    "preds=SVM_Model.predict(x_test)\n",
    "\n",
    "preds=scaler_y.inverse_transform(preds.reshape(-1,1))\n",
    "y_test=scaler_y.inverse_transform(y_test.reshape(-1,1))\n",
    "\n",
    "print(\"Best Parameters: \", SVM_Model.best_params_)\n",
    "print(\"Best Score: \", SVM_Model.best_score_)\n",
    "\n",
    "print(\"R2 score:\",metrics.r2_score(preds,y_test))\n",
    "print(\"MSE score:\",metrics.mean_squared_error(preds,y_test))\n",
    "print(\"MAE score:\",metrics.mean_absolute_error(preds,y_test))\n",
    "# Plotting scatter plots\n",
    "plt.scatter(preds,y_test)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Scatter Plot')\n",
    "plt.show()\n",
    "# Plotting residuals plots\n",
    "residuals = [predicted - actual for predicted, actual in zip(preds, y_test)]\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "# Preservation of models\n",
    "with open('SVM_model.pkl', 'wb') as f:\n",
    "    pickle.dump(SVM_Model, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction using Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using Random Forest Regression\n",
    "n_estimators = np.arange(20,40,step=1) \n",
    "max_features = [\"auto\", \"sqrt\", \"log2\"]\n",
    "max_depth = list(np.arange(20, 40, step=1)) + [None]\n",
    "min_samples_split = np.arange(2, 10, step=2)\n",
    "min_samples_leaf = [1, 2, 4] \n",
    "bootstrap = [True, False]\n",
    "param_grid = {\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"max_features\": max_features,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"min_samples_split\": min_samples_split,\n",
    "    \"min_samples_leaf\": min_samples_leaf,\n",
    "    \"bootstrap\": bootstrap,\n",
    "}\n",
    "rf=RandomForestRegressor(n_estimators=22,min_samples_leaf=1,min_samples_split=6,max_features=\"sqrt\",max_depth=37,bootstrap=False)\n",
    "# random_cv=RandomizedSearchCV(rf,param_grid,n_iter=100,cv=3,scoring=\"r2\",n_jobs=-1)\n",
    "rf.fit(x_train,y_train)\n",
    "preds=rf.predict(x_test)\n",
    "\n",
    "preds=scaler_y.inverse_transform(preds.reshape(-1,1))\n",
    "y_test=scaler_y.inverse_transform(y_test.reshape(-1,1))\n",
    "\n",
    "# print(\"Best Parameters: \", rf.best_params_)\n",
    "# print(\"Best Score: \", rf.best_score_)\n",
    "\n",
    "print(\"R2 score:\",metrics.r2_score(preds,y_test))\n",
    "print(\"MSE score:\",metrics.mean_squared_error(preds,y_test))\n",
    "print(\"MAE score:\",metrics.mean_absolute_error(preds,y_test))\n",
    "\n",
    "# Plotting scatter plots\n",
    "plt.scatter(preds,y_test)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Scatter Plot')\n",
    "plt.show()\n",
    "# Plotting residuals plots\n",
    "residuals = [predicted - actual for predicted, actual in zip(preds, y_test)]\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "# Preservation of models\n",
    "with open('Random_Forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "  table {\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "    width: 30%; /* 设置表格宽度为80% */\n",
    "    height: 80px; /* 设置表格高度为200像素 */\n",
    "    text-align: center; /* 将表格中的文本内容居中对齐 */\n",
    "  }\n",
    "  th, td {\n",
    "    font-size: 20px; /* 设置文字大小为16像素 */\n",
    "    font-weight: bold; /* 设置文字加粗 */\n",
    "  }\n",
    "  caption {\n",
    "    font-size: 24px; /* 设置标题文字大小为20像素 */\n",
    "    font-weight: bold; /* 设置标题文字加粗 */\n",
    "    margin-bottom: 10px;\n",
    "  }\n",
    "</style>\n",
    "<table>\n",
    "  <caption>Nonlinear SVM regression prediction</caption>\n",
    "  <tr>\n",
    "    <th>R2 score</th>\n",
    "    <th>MSE score</th>\n",
    "    <th>MAE score</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.8557</td>\n",
    "    <td>0.2133</td>\n",
    "    <td>0.22259</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<style>\n",
    "  .image-with-padding {\n",
    "    padding-right: 30px; /* 设置图片右侧间隔为10像素 */\n",
    "  }\n",
    "  .component {\n",
    "    margin-top: 20px; /* 设置组件上方距离为20像素 */\n",
    "  }\n",
    "</style>\n",
    "<div align=\"center\" class=\"component\"><img src='svm_scatter.png'class=\"image-with-padding\" alt=\"Image 1\"><img src='svm_residual.png' alt=\"Image 2\"></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Random forest regression<br>\n",
    "R2 score: 0.8530944968179189<br>\n",
    "MSE score: 0.1965843017716448<br>\n",
    "MAE score: 0.2040847203381215<br>\n",
    "<div align=\"center\"><img src='forest_scatter.png'><br></div>\n",
    "<div align=\"center\"><img src='forest_residual.png'><br></div> -->\n",
    "\n",
    "<style>\n",
    "  table {\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "    width: 30%; /* 设置表格宽度为80% */\n",
    "    height: 80px; /* 设置表格高度为200像素 */\n",
    "    text-align: center; /* 将表格中的文本内容居中对齐 */\n",
    "  }\n",
    "  th, td {\n",
    "    font-size: 20px; /* 设置文字大小为16像素 */\n",
    "    font-weight: bold; /* 设置文字加粗 */\n",
    "  }\n",
    "  caption {\n",
    "    font-size: 24px; /* 设置标题文字大小为20像素 */\n",
    "    font-weight: bold; /* 设置标题文字加粗 */\n",
    "    margin-bottom: 10px;\n",
    "  }\n",
    "</style>\n",
    "<table>\n",
    "  <caption>Random forest regression</caption>\n",
    "  <tr>\n",
    "    <th>R2 score</th>\n",
    "    <th>MSE score</th>\n",
    "    <th>MAE score</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0.8678</td>\n",
    "    <td>0.196</td>\n",
    "    <td>0.204</td>\n",
    "  </tr>\n",
    "</table>\n",
    "<style>\n",
    "  .image-with-padding {\n",
    "    padding-right: 30px; /* 设置图片右侧间隔为10像素 */\n",
    "  }\n",
    "  .component {\n",
    "    margin-top: 20px; /* 设置组件上方距离为20像素 */\n",
    "  }\n",
    "</style>\n",
    "<div align=\"center\" class=\"component\"><img src='forest_scatter.png'class=\"image-with-padding\" alt=\"Image 1\"><img src='forest_residual.png' alt=\"Image 2\"></div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Interface"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the ***file path*** of the test set to get the test results<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.feature_selection import chi2,SelectKBest\n",
    "from sklearn.model_selection import cross_val_score,ShuffleSplit,RandomizedSearchCV,learning_curve,train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics\n",
    "\n",
    "file_path=\"dataset_example.csv\"\n",
    "\n",
    "X_features=['SIO2', 'P2O5', 'ZRO2', 'NA2O', 'AL2O3', 'FE2O3', 'CAO', 'MgO', 'K2O',\n",
    "       'MnO', 'GEO2', 'Li2O', 'Ta2O5', 'ZNO', 'SRO', 'CdO', 'SnO2', 'B2O3',\n",
    "       'La2O3', 'Ga2O3', 'Y2O3', 'TIO2', 'Nb2O5', 'PBO', 'WO3', 'Sb2O3',\n",
    "       'Bi2O3', 'BAO', 'Cr2O3', 'BeO', 'CuO', 'Nd2O3', 'CeO2', 'Cs2O', 'AS2O3',\n",
    "       'SO3', 'Rb2O', 'MoO3', 'FeO', 'Ag2O', 'TEO2', 'V2O5', 'Sm2O3', 'Gd2O3',\n",
    "       'Er2O3', 'Yb2O3', 'H2O', 'SnO', 'O']\n",
    "X_features.insert(0,'DENSITY')\n",
    "\n",
    "val_data=pd.read_csv(file_path)\n",
    "\n",
    "val_data=val_data.drop(val_data.columns[21:35],axis=1)\n",
    "val_data.columns=val_data.iloc[0]\n",
    "val_data=val_data[1:]\n",
    "V_colums=val_data.columns\n",
    "\n",
    "num_rows=val_data.shape[0]# get rows num\n",
    "num_colums=val_data.shape[1]# get colums num\n",
    "\n",
    "temp=pd.DataFrame(np.zeros((num_rows+1,50-num_colums)))\n",
    "val_data=pd.concat([val_data,temp],axis=1,sort=False,ignore_index=False)# fill the val_data\n",
    "val_data=val_data.drop(val_data.index[-1])\n",
    "\n",
    "S_val_data=pd.DataFrame(np.zeros((num_rows,50)))\n",
    "S_val_data.index=range(1,len(S_val_data)+1)\n",
    "for label in V_colums:\n",
    "    index=X_features.index(label)\n",
    "    S_val_data.iloc[:,index]=val_data[label].copy()\n",
    "\n",
    "# print(S_val_data)\n",
    "\n",
    "val_x_colums=val_data.columns[1:]\n",
    "val_y_colums=val_data.columns[0]\n",
    "val_x_data=val_data[val_x_colums]\n",
    "val_y_data=val_data[val_y_colums]\n",
    "\n",
    "val_x_data=val_x_data.to_numpy()\n",
    "val_y_data=val_y_data.to_numpy()\n",
    "\n",
    "scaler_x_val = StandardScaler()\n",
    "scaler_y_val = StandardScaler()\n",
    "\n",
    "val_x_data = scaler_x_val.fit_transform(val_x_data)\n",
    "val_y_data = scaler_y_val.fit_transform(val_y_data.reshape(-1, 1))\n",
    "\n",
    "val_x_data=scaler_x_val.transform(val_x_data)\n",
    "val_y_data=scaler_y_val.transform(val_y_data.reshape(-1,1))\n",
    "\n",
    "# SVM \n",
    "with open('SVM_model.pkl', 'rb') as f:\n",
    "    SAVE_SVM = pickle.load(f)\n",
    "\n",
    "val_y_preds=SAVE_SVM.predict(val_x_data)\n",
    "\n",
    "val_y_preds=scaler_y_val.inverse_transform(val_y_preds.reshape(-1,1))\n",
    "val_y_data=scaler_y_val.inverse_transform(val_y_data.reshape(-1,1))\n",
    "\n",
    "print(\"SVM R2 score:\",metrics.r2_score(val_y_preds,val_y_data))\n",
    "print(\"SVM MSE score:\",metrics.mean_squared_error(val_y_preds,val_y_data))\n",
    "print(\"SVM MAE score:\",metrics.mean_absolute_error(val_y_preds,val_y_data))\n",
    "\n",
    "val_data=pd.read_csv(file_path)\n",
    "\n",
    "val_data=val_data.drop(val_data.columns[21:35],axis=1)\n",
    "val_data.columns=val_data.iloc[0]\n",
    "val_data=val_data[1:]\n",
    "V_colums=val_data.columns\n",
    "\n",
    "num_rows=val_data.shape[0]# get rows num\n",
    "num_colums=val_data.shape[1]# get colums num\n",
    "\n",
    "temp=pd.DataFrame(np.zeros((num_rows+1,50-num_colums)))\n",
    "val_data=pd.concat([val_data,temp],axis=1,sort=False,ignore_index=False)# fill the val_data\n",
    "val_data=val_data.drop(val_data.index[-1])\n",
    "\n",
    "S_val_data=pd.DataFrame(np.zeros((num_rows,50)))\n",
    "S_val_data.index=range(1,len(S_val_data)+1)\n",
    "for label in V_colums:\n",
    "    index=X_features.index(label)\n",
    "    S_val_data.iloc[:,index]=val_data[label].copy()\n",
    "\n",
    "# print(S_val_data)\n",
    "\n",
    "val_x_colums=val_data.columns[1:]\n",
    "val_y_colums=val_data.columns[0]\n",
    "val_x_data=val_data[val_x_colums]\n",
    "val_y_data=val_data[val_y_colums]\n",
    "\n",
    "val_x_data=val_x_data.to_numpy()\n",
    "val_y_data=val_y_data.to_numpy()\n",
    "\n",
    "scaler_x_val = StandardScaler()\n",
    "scaler_y_val = StandardScaler()\n",
    "\n",
    "val_x_data = scaler_x_val.fit_transform(val_x_data)\n",
    "val_y_data = scaler_y_val.fit_transform(val_y_data.reshape(-1, 1))\n",
    "\n",
    "val_x_data=scaler_x_val.transform(val_x_data)\n",
    "val_y_data=scaler_y_val.transform(val_y_data.reshape(-1,1))\n",
    "\n",
    "# Ramdon Forest\n",
    "with open('Random_Forest_model.pkl', 'rb') as f:\n",
    "    SAVE_Random_Forest = pickle.load(f)\n",
    "\n",
    "val_y_preds=SAVE_Random_Forest.predict(val_x_data)\n",
    "\n",
    "val_y_preds=scaler_y_val.inverse_transform(val_y_preds.reshape(-1,1))\n",
    "val_x_data=scaler_y_val.inverse_transform(val_x_data.reshape(-1,1))\n",
    "\n",
    "print(\"Random_Forest R2 score:\",metrics.r2_score(val_y_preds,val_y_data))\n",
    "print(\"Random_Forest MSE score:\",metrics.mean_squared_error(val_y_preds,val_y_data))\n",
    "print(\"Random_Forest MAE score:\",metrics.mean_absolute_error(val_y_preds,val_y_data))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
